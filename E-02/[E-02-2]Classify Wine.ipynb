{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "asian-think",
   "metadata": {},
   "source": [
    "# 와인 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-ocean",
   "metadata": {},
   "source": [
    "## 1) 필요 모듈 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "elect-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-collector",
   "metadata": {},
   "source": [
    "## 2) 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fluid-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-nickel",
   "metadata": {},
   "source": [
    "## 3) 데이터 이해\n",
    "- Feature Data 지정\n",
    "- Label Data 지정\n",
    "- Target Names 출력\n",
    "- Data Describe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-angola",
   "metadata": {},
   "source": [
    "### 키 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dated-istanbul",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-exploration",
   "metadata": {},
   "source": [
    "## Feature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "endless-cotton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'malic_acid',\n",
       " 'ash',\n",
       " 'alcalinity_of_ash',\n",
       " 'magnesium',\n",
       " 'total_phenols',\n",
       " 'flavanoids',\n",
       " 'nonflavanoid_phenols',\n",
       " 'proanthocyanins',\n",
       " 'color_intensity',\n",
       " 'hue',\n",
       " 'od280/od315_of_diluted_wines',\n",
       " 'proline']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-cooperative",
   "metadata": {},
   "source": [
    "- 알콜\n",
    "- 말릭 산\n",
    "- 애쉬\n",
    "- 마그네슘\n",
    "- 페놀의 토탈 양\n",
    "- 플레이버노이드\n",
    "- 색 진하기\n",
    "\n",
    "와인에 대한 도메인 지식이 없어서 그냥 다양한 정보가 있다는 것을 알겠다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "identical-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data = wine.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sunset-least",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "virtual-healing",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = pd.DataFrame(wine_data, columns=wine.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "innocent-financing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
      "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
      "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
      "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
      "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
      "..       ...         ...   ...                ...        ...            ...   \n",
      "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
      "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
      "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
      "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
      "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
      "\n",
      "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
      "0          3.06                  0.28             2.29             5.64  1.04   \n",
      "1          2.76                  0.26             1.28             4.38  1.05   \n",
      "2          3.24                  0.30             2.81             5.68  1.03   \n",
      "3          3.49                  0.24             2.18             7.80  0.86   \n",
      "4          2.69                  0.39             1.82             4.32  1.04   \n",
      "..          ...                   ...              ...              ...   ...   \n",
      "173        0.61                  0.52             1.06             7.70  0.64   \n",
      "174        0.75                  0.43             1.41             7.30  0.70   \n",
      "175        0.69                  0.43             1.35            10.20  0.59   \n",
      "176        0.68                  0.53             1.46             9.30  0.60   \n",
      "177        0.76                  0.56             1.35             9.20  0.61   \n",
      "\n",
      "     od280/od315_of_diluted_wines  proline  \n",
      "0                            3.92   1065.0  \n",
      "1                            3.40   1050.0  \n",
      "2                            3.17   1185.0  \n",
      "3                            3.45   1480.0  \n",
      "4                            2.93    735.0  \n",
      "..                            ...      ...  \n",
      "173                          1.74    740.0  \n",
      "174                          1.56    750.0  \n",
      "175                          1.56    835.0  \n",
      "176                          1.62    840.0  \n",
      "177                          1.60    560.0  \n",
      "\n",
      "[178 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "print(wine_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-clock",
   "metadata": {},
   "source": [
    "- 데이터는 모두 수치형 데이터이다.\n",
    "- 수치 범위가 컬럼마다 정규화가 필요해보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-windsor",
   "metadata": {},
   "source": [
    "## Label Data 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "flush-danish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['class_0', 'class_1', 'class_2'], dtype='<U7')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-bread",
   "metadata": {},
   "source": [
    "- 세 종류의 라벨이 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "opposite-municipality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "narrow-grace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-sentence",
   "metadata": {},
   "source": [
    "- 178개의 데이터 샘플에 대한 라벨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-starter",
   "metadata": {},
   "source": [
    "### 데이터 describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "diagnostic-participant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(wine.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-washington",
   "metadata": {},
   "source": [
    "## 4) train,test 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "simple-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(wine_data, wine.target,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=324)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "global-herald",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train : (142, 13), x_test : (36, 13)\n",
      "y_train : (142,), y_test : (36,)\n"
     ]
    }
   ],
   "source": [
    "print(f'x_train : {x_train.shape}, x_test : {x_test.shape}\\ny_train : {y_train.shape}, y_test : {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-christmas",
   "metadata": {},
   "source": [
    "## 5) 베이스 라인 모델\n",
    "- 전처리를 거치지 않은 원본 데이터를 의사결정나무 모델로 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "known-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = DecisionTreeClassifier()\n",
    "base.fit(x_train,y_train)\n",
    "base_pred = base.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "material-carol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        16\n",
      "           1       0.82      0.90      0.86        10\n",
      "           2       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.91      0.91      0.91        36\n",
      "weighted avg       0.92      0.92      0.92        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, base_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-concentration",
   "metadata": {},
   "source": [
    "- 92%의 정확도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-affairs",
   "metadata": {},
   "source": [
    "## 6) 데이터 전처리\n",
    "- 사이킷런이 제공하는 `MinMaxScaler` 사용한다.\n",
    "- 학습데이터를 기준으로 스케일러를 `fit()`한 후 학습 데이터와 테스트 데이터를 스케일링 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "general-rebel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.34029851 0.14031621 0.54248366 ... 0.78861789 0.34686347 0.0606777 ]\n",
      " [0.31044776 0.28063241 0.30718954 ... 0.30894309 0.73431734 0.07880221]\n",
      " [0.35223881 0.08893281 0.03267974 ... 0.6504065  0.65682657 0.34672971]\n",
      " ...\n",
      " [0.18208955 0.26086957 0.49673203 ... 0.42276423 0.53874539 0.31678487]\n",
      " [0.56716418 0.40909091 0.65359477 ... 0.23577236 0.37638376 0.2537431 ]\n",
      " [0.65671642 0.50592885 0.37908497 ... 0.06504065 0.08118081 0.31284476]]\n",
      "[[ 0.23283582  0.27272727  0.67973856  0.54787234  0.69565217  0.21602787\n",
      "   0.1371308   0.01886792  0.36277603  0.10409556  0.38211382  0.35793358\n",
      "   0.27344366]\n",
      " [ 0.54328358  0.16996047  0.53594771  0.35106383  0.27173913  0.52264808\n",
      "   0.42827004  0.24528302  0.33123028  0.22610922  0.49593496  0.86346863\n",
      "   0.58077226]\n",
      " [ 0.33731343  0.17193676  0.39869281  0.61702128  0.2173913   0.27874564\n",
      "   0.28481013  0.56603774  0.36277603  0.09982935  0.69105691  0.35793358\n",
      "   0.17100079]\n",
      " [ 0.67164179  0.17786561  0.74509804  0.2287234   0.43478261  0.56445993\n",
      "   0.49367089  0.39622642  0.29968454  0.28327645  0.49593496  0.5498155\n",
      "   0.47438928]\n",
      " [ 0.92238806  0.14624506  0.40522876  0.29787234  0.27173913  0.42508711\n",
      "   0.44092827  0.24528302  0.3659306   0.31740614  0.56097561  0.56457565\n",
      "   0.78959811]\n",
      " [ 0.3761194   0.48023715  0.33333333  0.36170213  0.19565217  0.65156794\n",
      "   0.55907173  0.60377358  0.75709779  0.08703072  0.76422764  0.56826568\n",
      "   0.10086682]\n",
      " [ 0.66865672  0.69960474  0.36601307  0.46808511  0.54347826  0.21254355\n",
      "   0.07383966  0.56603774  0.29652997  0.76109215  0.08943089  0.099631\n",
      "   0.43892829]\n",
      " [ 1.13432836  0.17786561  0.30718954  0.14893617  0.29347826  0.63414634\n",
      "   0.55696203  0.30188679  0.49526814  0.33447099  0.48780488  0.57564576\n",
      "   0.60441292]\n",
      " [ 0.3641791   0.19565217  0.2745098   0.41489362  0.10869565  0.23344948\n",
      "   0.35654008  0.45283019  0.38485804  0.18088737  0.42276423  0.69372694\n",
      "   0.18282112]\n",
      " [ 1.11044776  0.19565217  0.45098039  0.0106383   0.22826087  0.73867596\n",
      "   0.70675105  0.56603774  0.75709779  0.35153584  0.62601626  0.53136531\n",
      "   0.68715524]\n",
      " [ 0.46865672  0.11857708  0.13071895  0.38829787  0.19565217  0.16376307\n",
      "   0.21518987  0.30188679  0.29652997  0.09982935  0.45528455  0.54612546\n",
      "   0.22379827]\n",
      " [ 0.8358209   0.1798419   0.58823529  0.31914894  0.26086957  0.51219512\n",
      "   0.55907173  0.16981132  0.59305994  0.36860068  0.61788618  0.76752768\n",
      "   0.77777778]\n",
      " [ 0.79402985  0.49802372  0.54901961  0.46808511  0.40217391  0.29616725\n",
      "   0.0464135   0.69811321  0.12302839  0.39249147  0.3902439   0.19557196\n",
      "   0.31678487]\n",
      " [ 0.4         0.03952569 -0.22222222 -0.03191489  0.19565217  0.34843206\n",
      "   0.04852321  0.28301887  0.00315457  0.05716724  0.46341463  0.19557196\n",
      "   0.19070134]\n",
      " [ 0.83283582  0.19960474  0.47058824  0.14893617  0.44565217  1.01045296\n",
      "   0.71729958  0.35849057  0.46056782  0.49232082  0.43089431  0.72693727\n",
      "   0.71867612]\n",
      " [ 0.65970149  0.64031621  0.38562092  0.33510638  0.35869565  0.57839721\n",
      "   0.48312236  0.35849057  0.39432177  0.26279863  0.27642276  0.63099631\n",
      "   0.31678487]\n",
      " [ 0.93432836  0.34980237  0.50980392  0.46808511  0.22826087  0.24390244\n",
      "   0.07594937  0.58490566  0.26182965  0.71843003  0.11382114  0.15498155\n",
      "   0.30102443]\n",
      " [ 0.53134328  0.31027668  0.45751634  0.68085106  0.30434783  0.05923345\n",
      "   0.15822785  0.26415094  0.13249211  0.37713311  0.14634146  0.02583026\n",
      "   0.22222222]\n",
      " [ 0.94328358  0.16798419  0.50980392  0.28191489  0.41304348  0.80836237\n",
      "   0.75738397  0.35849057  0.45741325  0.6331058   0.6097561   0.56457565\n",
      "   1.10480693]\n",
      " [ 0.53432836  0.51976285  0.39215686  0.44148936  0.19565217  0.17421603\n",
      "   0.06751055  0.50943396  0.17665615  0.7662116   0.19512195  0.1697417\n",
      "   0.32072498]\n",
      " [ 0.76119403  0.18181818  0.43137255  0.42021277  0.39130435  0.65505226\n",
      "   0.60126582  0.16981132  0.48580442  0.47952218  0.49593496  0.58671587\n",
      "   0.97478329]\n",
      " [ 0.3641791   0.78656126  0.54901961  0.5212766   0.20652174  0.13937282\n",
      "   0.02742616  0.75471698  0.12302839  0.21928328  0.2195122  -0.00738007\n",
      "   0.34830575]\n",
      " [ 0.70746269  0.76284585  0.75816993  0.73404255  0.45652174  0.34843206\n",
      "   0.13080169  0.26415094  0.22082019  0.61604096  0.15447154  0.23247232\n",
      "   0.27738377]\n",
      " [ 0.31343284  0.0770751   0.52941176  0.68085106  0.08695652  0.3554007\n",
      "   0.26160338  0.50943396  0.31230284  0.07849829  0.67479675  0.52767528\n",
      "   0.27738377]\n",
      " [ 0.44179104  0.19565217  0.18300654  0.49468085  0.16304348  0.42508711\n",
      "   0.33333333  0.35849057  0.33753943  0.14163823  0.45528455  0.84132841\n",
      "   0.31048069]\n",
      " [ 1.00298507  0.22332016  0.49019608  0.18085106  0.2826087   0.52961672\n",
      "   0.45991561  0.32075472  0.49526814  0.3387372   0.43902439  0.84501845\n",
      "   0.79747833]\n",
      " [ 0.91641791  0.28063241  0.39215686  0.36170213  0.38043478  0.68641115\n",
      "   0.62869198  0.16981132  0.6214511   0.38139932  0.62601626  0.69372694\n",
      "   0.97084318]\n",
      " [ 0.60298507  0.25889328  0.99346405  0.73404255  0.58695652  0.57491289\n",
      "   0.49367089  0.64150943  0.47634069  0.19624573  0.52845528  0.70479705\n",
      "   0.43498818]\n",
      " [ 0.70447761  0.20355731  0.60130719  0.2606383   0.25        0.65156794\n",
      "   0.54852321  0.39622642  0.32807571  0.3003413   0.35772358  0.71217712\n",
      "   0.72261623]\n",
      " [ 0.54626866  0.12055336  0.40522876  0.36170213  0.56521739  0.18466899\n",
      "   0.19198312  0.1509434   0.16719243  0.24061433  0.22764228  0.\n",
      "   0.27738377]\n",
      " [ 0.3641791   0.62055336  0.32679739  0.38829787  0.45652174  0.13937282\n",
      "   0.092827    0.30188679  0.23028391  0.59129693  0.13821138  0.26199262\n",
      "   0.45468873]\n",
      " [ 0.4238806   0.45256917  0.61437908  0.84042553  0.29347826  0.32055749\n",
      "   0.05063291  0.94339623  0.23028391  0.53071672  0.15447154  0.16236162\n",
      "   0.47438928]\n",
      " [ 0.50447761  0.19960474  0.37908497  0.60106383  0.15217391  0.13937282\n",
      "   0.29957806  0.66037736  0.38485804  0.17235495  0.32520325  0.41697417\n",
      "   0.16548463]\n",
      " [ 0.8119403   0.19565217  0.46405229  0.25531915  0.20652174  0.56445993\n",
      "   0.51054852  0.30188679  0.44164038  0.36860068  0.54471545  0.59409594\n",
      "   0.82111899]\n",
      " [ 0.84477612  0.15217391  0.63398693  0.73404255  0.17391304  0.68641115\n",
      "   0.53164557  0.1509434   0.46056782  0.17918089  0.71544715  0.6900369\n",
      "   0.10401891]\n",
      " [ 0.81492537  0.15612648  0.65359477  0.44148936  0.67391304  0.68641115\n",
      "   0.50632911  0.69811321  0.29652997  0.35153584  0.62601626  0.63099631\n",
      "   0.75413712]]\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train)\n",
    "X_train = scaler.transform(x_train)\n",
    "X_test = scaler.transform(x_test)\n",
    "print(X_train)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 전체를 기준으로 스케일링을 진행했을 때의 코드\n",
    "'''X_train, X_test, y_train, y_test = train_test_split(wine_data_norm, wine.target,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=324)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-slovenia",
   "metadata": {},
   "source": [
    "## 7) 다양한 모델로 학습\n",
    "- `Decision Tree`\n",
    "- `Random Forest`\n",
    "- `SVM`\n",
    "- `SGD Classifier`\n",
    "- `Logistic Regression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "preceding-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "svm = SVC()\n",
    "sgd = SGDClassifier()\n",
    "logi = LogisticRegression()\n",
    "\n",
    "dt.fit(X_train,y_train)\n",
    "dt_pred = dt.predict(X_test)\n",
    "\n",
    "rf.fit(X_train,y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "svm.fit(X_train,y_train)\n",
    "svm_pred = svm.predict(X_test)\n",
    "\n",
    "sgd.fit(X_train,y_train)\n",
    "sgd_pred = sgd.predict(X_test)\n",
    "\n",
    "logi.fit(X_train,y_train)\n",
    "logi_pred = logi.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-western",
   "metadata": {},
   "source": [
    "# 8) 모델 평가\n",
    "### 사용한 평가 척도\n",
    "- `재현율`, `정밀도`, `정확도`를 전반적으로 보고자 한다.\n",
    "- `classification_report` 를 통해 카테고리 별 `재현율`과 `정밀도`를 보고 모든 카테고리의 `재현율`, `정밀도`의 평균을 통해 학습 성능을 평가할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "consecutive-latvia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========DecisionTree의 성능===========\n",
      "요약\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        16\n",
      "           1       0.83      1.00      0.91        10\n",
      "           2       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.94      0.95      0.94        36\n",
      "weighted avg       0.95      0.94      0.95        36\n",
      "\n",
      "정확도 : 0.9444444444444444\n",
      "정밀도 : 0.9444444444444445\n",
      "재현율 : 0.9458333333333333\n",
      "===========RandomForest의 성능===========\n",
      "요약\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        16\n",
      "           1       0.91      1.00      0.95        10\n",
      "           2       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.97      0.98      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "정확도 : 0.9722222222222222\n",
      "정밀도 : 0.9696969696969697\n",
      "재현율 : 0.9791666666666666\n",
      "===========SVM의 성능===========\n",
      "요약\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        16\n",
      "           1       0.91      1.00      0.95        10\n",
      "           2       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.97      0.98      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "정확도 : 0.9722222222222222\n",
      "정밀도 : 0.9696969696969697\n",
      "재현율 : 0.9791666666666666\n",
      "===========SGD의 성능===========\n",
      "요약\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "정확도 : 1.0\n",
      "정밀도 : 1.0\n",
      "재현율 : 1.0\n",
      "===========LogiticsRegression의 성능===========\n",
      "요약\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "정확도 : 1.0\n",
      "정밀도 : 1.0\n",
      "재현율 : 1.0\n",
      "===============총정리================\n",
      "    DecisionTree RandomForest       SVM  SGD LogiticsRegression\n",
      "정확도     0.944444     0.972222  0.972222  1.0                1.0\n",
      "정밀도     0.944444     0.969697  0.969697  1.0                1.0\n",
      "재현율     0.945833     0.979167  0.979167  1.0                1.0\n"
     ]
    }
   ],
   "source": [
    "model_dict = {'DecisionTree' : dt_pred, 'RandomForest' : rf_pred, 'SVM' : svm_pred, 'SGD': sgd_pred, 'LogiticRegression':logi_pred}\n",
    "measure=pd.DataFrame(columns=model_dict.keys(),index=['정확도','정밀도','재현율'])\n",
    "for k, v in model_dict.items():\n",
    "    accuracy=accuracy_score(y_test,v)\n",
    "    precisions=precision_score(y_test, v, average=None)\n",
    "    recalls=recall_score(y_test,v, average=None)\n",
    "    measure[k]['정확도']=accuracy\n",
    "    measure[k]['정밀도']=sum(precisions)/3\n",
    "    measure[k]['재현율']=sum(recalls)/3\n",
    "    print(f'==========={k}의 성능===========')\n",
    "    print('요약')\n",
    "    print(classification_report(y_test,v))\n",
    "    print(f'정확도 : {accuracy}')\n",
    "    print(f'정밀도 : {sum(precisions)/3}')\n",
    "    print(f'재현율 : {sum(recalls)/3}')\n",
    "    \n",
    "print('===============총정리================')\n",
    "print(measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-yield",
   "metadata": {},
   "source": [
    "## 전처리 전/후 모델 학습 성능 비교\n",
    "\n",
    "- 다른 모델에서는 얼마나 차이가 있을지 궁금해져서 정규화 하기 이전 데이터로 다시 학습을 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "pressing-yield",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "base_dt = DecisionTreeClassifier()\n",
    "base_rf = RandomForestClassifier()\n",
    "base_svm = SVC()\n",
    "base_sgd = SGDClassifier()\n",
    "base_logi = LogisticRegression()\n",
    "\n",
    "base_dt.fit(x_train,y_train)\n",
    "base_dt_pred = base_dt.predict(x_test)\n",
    "\n",
    "base_rf.fit(x_train,y_train)\n",
    "base_rf_pred = base_rf.predict(x_test)\n",
    "\n",
    "base_svm.fit(x_train,y_train)\n",
    "base_svm_pred = base_svm.predict(x_test)\n",
    "\n",
    "base_sgd.fit(x_train,y_train)\n",
    "base_sgd_pred = base_sgd.predict(x_test)\n",
    "\n",
    "base_logi.fit(x_train,y_train)\n",
    "base_logi_pred = base_logi.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "united-sensitivity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========DecisionTree의 성능===========\n",
      "요약\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        16\n",
      "           1       0.82      0.90      0.86        10\n",
      "           2       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.91      0.91      0.91        36\n",
      "weighted avg       0.92      0.92      0.92        36\n",
      "\n",
      "정확도 : 0.9166666666666666\n",
      "정밀도 : 0.9060606060606061\n",
      "재현율 : 0.9125\n",
      "===========RandomForest의 성능===========\n",
      "요약\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        16\n",
      "           1       0.91      1.00      0.95        10\n",
      "           2       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.97      0.98      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "정확도 : 0.9722222222222222\n",
      "정밀도 : 0.9696969696969697\n",
      "재현율 : 0.9791666666666666\n",
      "===========SVM의 성능===========\n",
      "요약\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88        16\n",
      "           1       0.56      1.00      0.71        10\n",
      "           2       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.69        36\n",
      "   macro avg       0.46      0.65      0.53        36\n",
      "weighted avg       0.52      0.69      0.59        36\n",
      "\n",
      "정확도 : 0.6944444444444444\n",
      "정밀도 : 0.46296296296296297\n",
      "재현율 : 0.6458333333333334\n",
      "===========SGD의 성능===========\n",
      "요약\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90        16\n",
      "           1       0.48      1.00      0.65        10\n",
      "           2       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.67        36\n",
      "   macro avg       0.47      0.62      0.52        36\n",
      "weighted avg       0.55      0.67      0.58        36\n",
      "\n",
      "정확도 : 0.6666666666666666\n",
      "정밀도 : 0.4698412698412698\n",
      "재현율 : 0.625\n",
      "===========LogiticsRegression의 성능===========\n",
      "요약\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        16\n",
      "           1       0.83      1.00      0.91        10\n",
      "           2       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.94      0.95      0.94        36\n",
      "weighted avg       0.95      0.94      0.95        36\n",
      "\n",
      "정확도 : 0.9444444444444444\n",
      "정밀도 : 0.9444444444444445\n",
      "재현율 : 0.9458333333333333\n",
      "===============전처리 안한 데이터 총정리================\n",
      "    DecisionTree RandomForest       SVM       SGD LogiticsRegression\n",
      "정확도     0.916667     0.972222  0.694444  0.666667           0.944444\n",
      "정밀도     0.906061     0.969697  0.462963  0.469841           0.944444\n",
      "재현율     0.912500     0.979167  0.645833  0.625000           0.945833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_dict = {'DecisionTree' : base_dt_pred, 'RandomForest' : base_rf_pred, 'SVM' : base_svm_pred, 'SGD': base_sgd_pred, 'LogiticRegression':base_logi_pred}\n",
    "base_measure=pd.DataFrame(columns=model_dict.keys(),index=['정확도','정밀도','재현율'])\n",
    "for k, v in model_dict.items():\n",
    "    accuracy=accuracy_score(y_test,v)\n",
    "    precisions=precision_score(y_test, v, average=None)\n",
    "    recalls=recall_score(y_test,v, average=None)\n",
    "    base_measure[k]['정확도']=accuracy\n",
    "    base_measure[k]['정밀도']=sum(precisions)/3\n",
    "    base_measure[k]['재현율']=sum(recalls)/3\n",
    "    print(f'==========={k}의 성능===========')\n",
    "    print('요약')\n",
    "    print(classification_report(y_test,v))\n",
    "    print(f'정확도 : {accuracy}')\n",
    "    print(f'정밀도 : {sum(precisions)/3}')\n",
    "    print(f'재현율 : {sum(recalls)/3}')\n",
    "    \n",
    "print('===============전처리 안한 데이터 총정리================')\n",
    "print(base_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "descending-column",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========전처리 전============\n",
      "    DecisionTree RandomForest       SVM       SGD LogiticsRegression\n",
      "정확도     0.916667     0.972222  0.694444  0.666667           0.944444\n",
      "정밀도     0.906061     0.969697  0.462963  0.469841           0.944444\n",
      "재현율     0.912500     0.979167  0.645833  0.625000           0.945833\n",
      "===========전처리 후============\n",
      "    DecisionTree RandomForest       SVM  SGD LogiticsRegression\n",
      "정확도     0.944444     0.972222  0.972222  1.0                1.0\n",
      "정밀도     0.944444     0.969697  0.969697  1.0                1.0\n",
      "재현율     0.945833     0.979167  0.979167  1.0                1.0\n"
     ]
    }
   ],
   "source": [
    "print('===========전처리 전============')\n",
    "print(base_measure)\n",
    "print('===========전처리 후============')\n",
    "print(measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-medicaid",
   "metadata": {},
   "source": [
    "- 수치형 데이터의 전처리 성능은 모델에 따라 영향을 많이 받는다.\n",
    "\n",
    "- 스케일링을 할 때의 데이터셋이 모집단인지 분리된 학습 데이터 셋인지 여부가 학습 성능에 미치는 영향도 생각외로 컸다.\n",
    "\n",
    "- `MinMaxScaler`를 적용한 후 데이터 셋을 분리했을 때는 `RandomForest` 모델의 정확도, 정밀도, 재현율이 1이었는데 학습, 테스트 데이터 셋을 분리한 후 학습 데이터에 스케일러를 `fit()` 한 후 테스트 데이터에 적용하니 전처리 전과 후에 같은 수치가 나왔다.\n",
    "\n",
    "- 그러나 생각해보면 실제 모델이 사용될 때는 이미 학습이 완료된 후 들어오는 새로운 데이터에 대해 예측해야할 것이니 학습 데이터 셋을 기준으로 스케일링을 진행하는 것이 논리적으로 더 타당해보인다.\n",
    "\n",
    "- `SVM`, `SGD`, `LogisticRegression`은 역시 데이터가 가우시안 분포를 가지고 있다는 가정하에 구현된 모델이어서 그런지 `MinMaxScaler`를 적용한 후가 월등히 정확도가 높았다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-integral",
   "metadata": {},
   "source": [
    "# 추후 학습 방향\n",
    "- `MinMaxScaler` 외의 스케일러를 적용했을 때의 성능 변화를 알아보고 싶다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
